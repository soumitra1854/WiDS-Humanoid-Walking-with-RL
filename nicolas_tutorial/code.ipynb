{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```Import Dependencies```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: stable-baselines3[extra] in /home/soumitra/.local/lib/python3.12/site-packages (2.4.0)\n",
      "Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /home/soumitra/.local/lib/python3.12/site-packages (from stable-baselines3[extra]) (1.0.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.20 in /home/soumitra/.local/lib/python3.12/site-packages (from stable-baselines3[extra]) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.13 in /home/soumitra/.local/lib/python3.12/site-packages (from stable-baselines3[extra]) (2.5.1)\n",
      "Requirement already satisfied: cloudpickle in /home/soumitra/.local/lib/python3.12/site-packages (from stable-baselines3[extra]) (3.1.0)\n",
      "Requirement already satisfied: pandas in /home/soumitra/.local/lib/python3.12/site-packages (from stable-baselines3[extra]) (2.2.3)\n",
      "Requirement already satisfied: matplotlib in /home/soumitra/.local/lib/python3.12/site-packages (from stable-baselines3[extra]) (3.9.2)\n",
      "Requirement already satisfied: opencv-python in /home/soumitra/.local/lib/python3.12/site-packages (from stable-baselines3[extra]) (4.10.0.84)\n",
      "Requirement already satisfied: pygame in /home/soumitra/.local/lib/python3.12/site-packages (from stable-baselines3[extra]) (2.6.1)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in /home/soumitra/.local/lib/python3.12/site-packages (from stable-baselines3[extra]) (2.18.0)\n",
      "Requirement already satisfied: psutil in /home/soumitra/.local/lib/python3.12/site-packages (from stable-baselines3[extra]) (6.0.0)\n",
      "Requirement already satisfied: tqdm in /home/soumitra/.local/lib/python3.12/site-packages (from stable-baselines3[extra]) (4.66.5)\n",
      "Requirement already satisfied: rich in /usr/lib/python3/dist-packages (from stable-baselines3[extra]) (13.7.1)\n",
      "Requirement already satisfied: ale-py>=0.9.0 in /home/soumitra/.local/lib/python3.12/site-packages (from stable-baselines3[extra]) (0.10.1)\n",
      "Requirement already satisfied: pillow in /usr/lib/python3/dist-packages (from stable-baselines3[extra]) (10.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/lib/python3/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3[extra]) (4.10.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /home/soumitra/.local/lib/python3.12/site-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3[extra]) (0.0.4)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/soumitra/.local/lib/python3.12/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/soumitra/.local/lib/python3.12/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.68.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/soumitra/.local/lib/python3.12/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.7)\n",
      "Requirement already satisfied: packaging in /home/soumitra/.local/lib/python3.12/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /home/soumitra/.local/lib/python3.12/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (5.28.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (68.1.2)\n",
      "Requirement already satisfied: six>1.9 in /usr/lib/python3/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/soumitra/.local/lib/python3.12/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/soumitra/.local/lib/python3.12/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.1)\n",
      "Requirement already satisfied: filelock in /home/soumitra/.local/lib/python3.12/site-packages (from torch>=1.13->stable-baselines3[extra]) (3.16.1)\n",
      "Requirement already satisfied: networkx in /home/soumitra/.local/lib/python3.12/site-packages (from torch>=1.13->stable-baselines3[extra]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/soumitra/.local/lib/python3.12/site-packages (from torch>=1.13->stable-baselines3[extra]) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/soumitra/.local/lib/python3.12/site-packages (from torch>=1.13->stable-baselines3[extra]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/soumitra/.local/lib/python3.12/site-packages (from torch>=1.13->stable-baselines3[extra]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/soumitra/.local/lib/python3.12/site-packages (from torch>=1.13->stable-baselines3[extra]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/soumitra/.local/lib/python3.12/site-packages (from torch>=1.13->stable-baselines3[extra]) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/soumitra/.local/lib/python3.12/site-packages (from torch>=1.13->stable-baselines3[extra]) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/soumitra/.local/lib/python3.12/site-packages (from torch>=1.13->stable-baselines3[extra]) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/soumitra/.local/lib/python3.12/site-packages (from torch>=1.13->stable-baselines3[extra]) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/soumitra/.local/lib/python3.12/site-packages (from torch>=1.13->stable-baselines3[extra]) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/soumitra/.local/lib/python3.12/site-packages (from torch>=1.13->stable-baselines3[extra]) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/soumitra/.local/lib/python3.12/site-packages (from torch>=1.13->stable-baselines3[extra]) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/soumitra/.local/lib/python3.12/site-packages (from torch>=1.13->stable-baselines3[extra]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/soumitra/.local/lib/python3.12/site-packages (from torch>=1.13->stable-baselines3[extra]) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/soumitra/.local/lib/python3.12/site-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/soumitra/.local/lib/python3.12/site-packages (from torch>=1.13->stable-baselines3[extra]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/soumitra/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.13->stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/soumitra/.local/lib/python3.12/site-packages (from matplotlib->stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/soumitra/.local/lib/python3.12/site-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/soumitra/.local/lib/python3.12/site-packages (from matplotlib->stable-baselines3[extra]) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/soumitra/.local/lib/python3.12/site-packages (from matplotlib->stable-baselines3[extra]) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib->stable-baselines3[extra]) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/lib/python3/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->stable-baselines3[extra]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/soumitra/.local/lib/python3.12/site-packages (from pandas->stable-baselines3[extra]) (2024.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/lib/python3/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/lib/python3/dist-packages (from rich->stable-baselines3[extra]) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/lib/python3/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/lib/python3/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install 'stable-baselines3[extra]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```Load Environment```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = 'CartPole-v1'\n",
    "env = gym.make(environment_name, render_mode='human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soumitra/.local/lib/python3.12/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 0 Score: 27.0\n",
      "Episodes: 1 Score: 31.0\n",
      "Episodes: 2 Score: 24.0\n",
      "Episodes: 3 Score: 23.0\n",
      "Episodes: 4 Score: 23.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(episodes):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, _,  info = env.step(action)\n",
    "        score += reward\n",
    "    print(f\"Episodes: {episode} Score: {score}\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "    \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Args:\u001b[0m\n",
      "\u001b[0;34m            action: The environment step action\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Returns:\u001b[0m\n",
      "\u001b[0;34m            The environment step ``(observation, reward, terminated, truncated, info)`` with `truncated=True`\u001b[0m\n",
      "\u001b[0;34m            if the number of steps elapsed >= max episode steps\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mtruncated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      ~/.local/lib/python3.12/site-packages/gym/wrappers/time_limit.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "env.step??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```Understanding The Environment```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.5758061e+00,  1.1205703e+38,  7.5159818e-02, -1.5981989e+38],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```Train an RL model```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m environment_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCartPole-v1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mMonitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgym\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[43menvironment_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrender_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m env \u001b[38;5;241m=\u001b[39m DummyVecEnv([\u001b[38;5;28;01mlambda\u001b[39;00m: env])\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m'\u001b[39m, env, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/stable_baselines3/common/monitor.py:40\u001b[0m, in \u001b[0;36mMonitor.__init__\u001b[0;34m(self, env, filename, allow_early_resets, reset_keywords, info_keywords, override_existing)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     33\u001b[0m     env: gym\u001b[38;5;241m.\u001b[39mEnv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m     override_existing: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     39\u001b[0m ):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults_writer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/gymnasium/core.py:310\u001b[0m, in \u001b[0;36mWrapper.__init__\u001b[0;34m(self, env)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wraps an environment to allow a modular transformation of the :meth:`step` and :meth:`reset` methods.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \n\u001b[1;32m    306\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;124;03m    env: The environment to wrap\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;241m=\u001b[39m env\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(env, Env)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_action_space: spaces\u001b[38;5;241m.\u001b[39mSpace[WrapperActType] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_observation_space: spaces\u001b[38;5;241m.\u001b[39mSpace[WrapperObsType] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "environment_name = 'CartPole-v1'\n",
    "env = Monitor(gym.make(environment_name, render_mode=None))\n",
    "env = DummyVecEnv([lambda: env])\n",
    "model = PPO('MlpPolicy', env, verbose=1, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 856  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 2    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 584          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068477746 |\n",
      "|    clip_fraction        | 0.0402       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.543       |\n",
      "|    explained_variance   | 0.879        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0429       |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00406     |\n",
      "|    value_loss           | 9.4          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 548          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022979504 |\n",
      "|    clip_fraction        | 0.0397       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.533       |\n",
      "|    explained_variance   | 0.655        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.229        |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -7.38e-05    |\n",
      "|    value_loss           | 4.63         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 535         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002235223 |\n",
      "|    clip_fraction        | 0.00937     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.546      |\n",
      "|    explained_variance   | 0.561       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.584       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.000599   |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 551          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068394495 |\n",
      "|    clip_fraction        | 0.0341       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.536       |\n",
      "|    explained_variance   | 0.131        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.155        |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00167     |\n",
      "|    value_loss           | 1.8          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 562           |\n",
      "|    iterations           | 6             |\n",
      "|    time_elapsed         | 21            |\n",
      "|    total_timesteps      | 12288         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027896615 |\n",
      "|    clip_fraction        | 0.00205       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.546        |\n",
      "|    explained_variance   | 0.0118        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 7.34          |\n",
      "|    n_updates            | 150           |\n",
      "|    policy_gradient_loss | 0.00142       |\n",
      "|    value_loss           | 23.4          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 570         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003156608 |\n",
      "|    clip_fraction        | 0.0125      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.523      |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.534       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.004      |\n",
      "|    value_loss           | 31.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 578          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061997473 |\n",
      "|    clip_fraction        | 0.0441       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.527       |\n",
      "|    explained_variance   | 0.503        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.151        |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00714     |\n",
      "|    value_loss           | 1.43         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 584         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007054823 |\n",
      "|    clip_fraction        | 0.0913      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.51       |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.022       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    value_loss           | 0.29        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 588          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 34           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032534674 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.512       |\n",
      "|    explained_variance   | 0.291        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.636        |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    value_loss           | 18           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x76705d9f7ec0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```Save and Reload Model```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_path = os.path.join('training', 'saved_models', 'ppo_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(ppo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soumitra/.local/lib/python3.12/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load(ppo_path, env = env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```Evaluate the Model```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soumitra/.local/lib/python3.12/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 500.0 +/- 0.0\n"
     ]
    }
   ],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n",
    "print(f\"Mean reward: {mean_reward} +/- {std_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03699933  0.03939426 -0.01058249  0.03432285]]\n"
     ]
    }
   ],
   "source": [
    "print(env.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 529.0\n"
     ]
    }
   ],
   "source": [
    "# Test the Trained Model with Rendering\n",
    "test_env = gym.make(environment_name, render_mode='human')\n",
    "obs, _ = test_env.reset()\n",
    "done = False\n",
    "score = 0\n",
    "while not done:\n",
    "    test_env.render()\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, reward, done, _, info = test_env.step(action)\n",
    "    score += reward\n",
    "print(f\"Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
